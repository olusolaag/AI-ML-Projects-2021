{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sentiment-analysis.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOV+X0/C+2fDhZlFRg+yb94",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olusolaag/AI-ML-Projects-2021/blob/main/sentiment_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhsnDhztm2n9"
      },
      "source": [
        "# Movie review sentiment analysis using IMDB dataset and keras (deep learning)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kysTo6nXqzBe",
        "outputId": "cdace3fa-75c8-4b57-f8ad-4b45836160c2"
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (1.5.12)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle) (5.0.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle) (2021.5.30)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle) (4.62.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqrrOOv_sM_P",
        "outputId": "6a99b6e3-d382-41c3-8139-1c983552c8be"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "RZuL6YpEytvS",
        "outputId": "4a008d46-51a8-4f2f-da97-a7b1bf28b44c"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-be660f40-fc78-4342-8c65-efef7ddc45fa\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-be660f40-fc78-4342-8c65-efef7ddc45fa\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"olusolaag\",\"key\":\"9a421f26f1a18c84f0bb87afe5493d83\"}'}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWzM99L8wB6g"
      },
      "source": [
        "!pip install -q kaggle"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH_T5b-GwQsP"
      },
      "source": [
        "!mkdir -p ~/.kaggle"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xtx66o-awZNw"
      },
      "source": [
        "!cp kaggle.json ~/.kaggle"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iD0N-xW7wim_",
        "outputId": "9473153d-9715-417c-ab74-7f42d5af3edc"
      },
      "source": [
        "!ls ~/.kaggle"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7UIrMmLwpJw"
      },
      "source": [
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Xm96R2Pw0Av"
      },
      "source": [
        "!mkdir sent-analysis"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFLLuKmBw_dg",
        "outputId": "815d1e4e-5a04-43eb-b307-4c170ae25b4f"
      },
      "source": [
        "!kaggle datasets download -d lakshmi25npathi/imdb-dataset-of-50k-movie-reviews -p sent-analysis"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading imdb-dataset-of-50k-movie-reviews.zip to sent-analysis\n",
            " 86% 22.0M/25.7M [00:00<00:00, 14.8MB/s]\n",
            "100% 25.7M/25.7M [00:00<00:00, 40.6MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzWnvCvB0LSR",
        "outputId": "d4dffa6c-9728-4339-efef-b68327370571"
      },
      "source": [
        "!unzip /content/sent-analysis/imdb-dataset-of-50k-movie-reviews.zip"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/sent-analysis/imdb-dataset-of-50k-movie-reviews.zip\n",
            "  inflating: IMDB Dataset.csv        \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJB2R5Yt-7o1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e419197-0bc6-4c6f-f1ac-f86b5f754c64"
      },
      "source": [
        "! pip install contractions\n",
        "! pip install inflect\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.0.52-py2.py3-none-any.whl (7.2 kB)\n",
            "Collecting textsearch>=0.0.21\n",
            "  Downloading textsearch-0.0.21-py2.py3-none-any.whl (7.5 kB)\n",
            "Collecting anyascii\n",
            "  Downloading anyascii-0.2.0-py3-none-any.whl (283 kB)\n",
            "\u001b[K     |████████████████████████████████| 283 kB 4.1 MB/s \n",
            "\u001b[?25hCollecting pyahocorasick\n",
            "  Downloading pyahocorasick-1.4.2.tar.gz (321 kB)\n",
            "\u001b[K     |████████████████████████████████| 321 kB 41.5 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
            "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.2-cp37-cp37m-linux_x86_64.whl size=85459 sha256=03285e76d278c8d0ed07ec7f0584f1f03b9a7a577fd56f3874040d09dc6782d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/25/19/a6/8f363d9939162782bb8439d886469756271abc01f76fbd790f\n",
            "Successfully built pyahocorasick\n",
            "Installing collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.2.0 contractions-0.0.52 pyahocorasick-1.4.2 textsearch-0.0.21\n",
            "Requirement already satisfied: inflect in /usr/local/lib/python3.7/dist-packages (2.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDR9DHLWaRbl"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "from numpy import array\n",
        "import contractions # to remove contractions like don't\n",
        "import inflect # to convert digits to text\n",
        "from numpy import array\n",
        "from tensorflow.keras.preprocessing.text import one_hot\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.layers.core import Activation, Dropout, Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import GlobalMaxPooling1D\n",
        "from keras.layers.embeddings import Embedding\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQQZZMHR_Oo0",
        "outputId": "d82f0ce0-dfa9-43c8-cd68-bbb05049050a"
      },
      "source": [
        "# load dataset and check for null values\n",
        "movie_reviews = pd.read_csv(\"/content/IMDB Dataset.csv\")\n",
        "\n",
        "movie_reviews.isnull().values.any()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "ymd4u1kA_1uO",
        "outputId": "3e9a1895-a40a-4a73-b5c2-850a9f39d2fb"
      },
      "source": [
        "print(movie_reviews.shape)\n",
        "movie_reviews.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50000, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>One of the other reviewers has mentioned that ...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I thought this was a wonderful way to spend ti...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Basically there's a family where a little boy ...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review sentiment\n",
              "0  One of the other reviewers has mentioned that ...  positive\n",
              "1  A wonderful little production. <br /><br />The...  positive\n",
              "2  I thought this was a wonderful way to spend ti...  positive\n",
              "3  Basically there's a family where a little boy ...  negative\n",
              "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "DAqsYJ_uAXk9",
        "outputId": "12fd64dd-f1a2-4723-f05d-c745ea3b144f"
      },
      "source": [
        "# Let us view one of the reviews\n",
        "movie_reviews[\"review\"][3]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Basically there's a family where a little boy (Jake) thinks there's a zombie in his closet & his parents are fighting all the time.<br /><br />This movie is slower than a soap opera... and suddenly, Jake decides to become Rambo and kill the zombie.<br /><br />OK, first of all when you're going to make a film you must Decide if its a thriller or a drama! As a drama the movie is watchable. Parents are divorcing & arguing like in real life. And then we have Jake with his closet which totally ruins all the film! I expected to see a BOOGEYMAN similar movie, and instead i watched a drama with some meaningless thriller spots.<br /><br />3 out of 10 just for the well playing parents & descent dialogs. As for the shots with Jake: just ignore them.\""
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1grXtVTVAdUF"
      },
      "source": [
        "# create a function to remove html tags, punctuations, special characters etc. from the review text\n",
        "\n",
        "# def remove_round_brackets(data): # function remove backets and special characters\n",
        "#   return re.sub('\\(.*?#@%&!\\)','',data)\n",
        "\n",
        "\n",
        "\n",
        "def number_to_text(data): #function converts digits to word\n",
        "  temp_str = data.split()\n",
        "  string = []\n",
        "  for i in temp_str:\n",
        "    # if the word is digit, converted to \n",
        "    # word else the sequence continues\n",
        "    if i.isdigit():\n",
        "      temp = inflect.engine().number_to_words(i)\n",
        "      string.append(temp)\n",
        "    else:\n",
        "      string.append(i)\n",
        "  return temp_str\n",
        "\n",
        "\n",
        "def preprocess_text(sen):\n",
        "    # PRE-PROCESS A GIVEN REVIEW\n",
        "    # sen = ' '.join(map(str, sen))\n",
        "    sen = re.sub('<.*?>', ' ', sen) # remove html tag\n",
        "    sen = re.sub(r'https\\S', ' ', sen) # remove url\n",
        "    sen = re.sub(r'[^\\w\\s]', '', sen) #\n",
        "    # sen = re.sub('[^a-zA-Z]', ' ', sen)    # remove non alphabet. This removes digits which are also essential\n",
        "    sen = contractions.fix(sen)\n",
        "    sen = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sen)    # remove Single characters\n",
        "    sen = re.sub(r'\\s+', ' ', sen)     # remove multiple spaces\n",
        "    sen = sen.lower() # lower case\n",
        "    return sen"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTjujHnWAxLd"
      },
      "source": [
        "# Store the preprocessed reviews in a new list\n",
        "X = []\n",
        "sentences = list(movie_reviews['review'])\n",
        "\n",
        "for sen in sentences:\n",
        "  \n",
        "  X.append(preprocess_text(sen))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOMLdcDHBE0O",
        "outputId": "8f9d05b4-defc-4837-97b4-e4c135a6b8cd"
      },
      "source": [
        "print(X[3])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "basically there is family where little boy jake thinks there is zombie in his closet his parents are fighting all the time this movie is slower than soap opera and suddenly jake decides to become rambo and kill the zombie ok first of all when you are going to make film you must decide if its thriller or drama as drama the movie is watchable parents are divorcing arguing like in real life and then we have jake with his closet which totally ruins all the film expected to see boogeyman similar movie and instead watched drama with some meaningless thriller spots 3 out of 10 just for the well playing parents descent dialogs as for the shots with jake just ignore them\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-kFMtmcv6as"
      },
      "source": [
        "# Convert labels to integers\n",
        "y = movie_reviews['sentiment']\n",
        "y = np.array(list(map(lambda x: 1 if x==\"positive\" else 0, y)))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLuY71VzwK1A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7af3f5f-2630-4d32-a3d5-f2baecb3e45f"
      },
      "source": [
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
        "\n",
        "print('Train Set',len(X_train))\n",
        "print('Test Set',len(X_test))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train Set 40000\n",
            "Test Set 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdfCLoHmykfX",
        "outputId": "8a127d9f-8be4-41ef-efcf-db73e6a0421b"
      },
      "source": [
        "print(X_train[3])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "this latterday fulci schlocker is totally abysmal concoction dealing with an incurable gambler brett halsey who decides bluebeardstyle to pay off his everrising debts by seducing some of the ugliest bitches you will ever lay your eyes on and who just happen to be wealthy widows the fulcipenned script also contrives to incorporate few blackly comedic elements which only result in some unfunny business involving corpse which will not stay put an opera singer victim who will not stop singing etc not to mention doppelganger theme straight out of the student of prague although in this case the two personas communicate via prerecorded radio messages in the end cannot say am surprised that this film shows no sign of the sophistication of mario bavas hatchet for the honeymoon 1970 which it resembles in several ways and that it is content to merely pile up the disgustingly gory but nonetooconvincing effects of dismembered limbs and squashed or melting faces with which alas fulci had by then become completely associated\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA-C8sYnwyrR"
      },
      "source": [
        "# Tokenizer class from the keras.preprocessing.text module creates a word-to-index integer dictionary\n",
        "\n",
        "tokenizer = Tokenizer(num_words=5000) #nb_words: None or int. Maximum number of words to work with (if set, tokenization will be restricted to the top nb_words most common words in the dataset)\n",
        "\n",
        "# https://stackoverflow.com/questions/51956000/what-does-keras-tokenizer-method-exactly-do\n",
        "\"\"\"fit_on_texts Updates internal vocabulary based on a list of texts. \n",
        "This method creates the vocabulary index based on word frequency. \n",
        "So if you give it something like, \"The cat sat on the mat.\" \n",
        "It will create a dictionary s.t. word_index[\"the\"] = 1; \n",
        "word_index[\"cat\"] = 2 it is word -> index dictionary so every word gets a unique integer value. \n",
        "0 is reserved for padding. So lower integer means more \n",
        "frequent word (often the first few are stop words because they appear a lot).\"\"\"\n",
        "tokenizer.fit_on_texts(X_train) \n",
        "\"\"\"texts_to_sequences Transforms each text in texts to a sequence of integers. \n",
        "So it basically takes each word in the text and replaces it with its corresponding \n",
        "integer value from the word_index dictionary.\"\"\"\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train)\n",
        "X_test = tokenizer.texts_to_sequences(X_test)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMeiDShPuN0o",
        "outputId": "5226e9a8-0e40-4699-9269-1d1e053059a7"
      },
      "source": [
        "X_train[3]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[8,\n",
              " 3514,\n",
              " 5,\n",
              " 427,\n",
              " 4368,\n",
              " 1876,\n",
              " 14,\n",
              " 31,\n",
              " 32,\n",
              " 1029,\n",
              " 4,\n",
              " 978,\n",
              " 121,\n",
              " 22,\n",
              " 30,\n",
              " 46,\n",
              " 3,\n",
              " 1,\n",
              " 18,\n",
              " 57,\n",
              " 118,\n",
              " 4114,\n",
              " 119,\n",
              " 488,\n",
              " 19,\n",
              " 2,\n",
              " 32,\n",
              " 38,\n",
              " 534,\n",
              " 4,\n",
              " 23,\n",
              " 2790,\n",
              " 1,\n",
              " 217,\n",
              " 81,\n",
              " 4,\n",
              " 163,\n",
              " 1629,\n",
              " 746,\n",
              " 61,\n",
              " 60,\n",
              " 897,\n",
              " 6,\n",
              " 46,\n",
              " 1872,\n",
              " 946,\n",
              " 1132,\n",
              " 3368,\n",
              " 61,\n",
              " 57,\n",
              " 10,\n",
              " 734,\n",
              " 256,\n",
              " 31,\n",
              " 1361,\n",
              " 1820,\n",
              " 1379,\n",
              " 32,\n",
              " 57,\n",
              " 10,\n",
              " 564,\n",
              " 1112,\n",
              " 505,\n",
              " 10,\n",
              " 4,\n",
              " 707,\n",
              " 729,\n",
              " 767,\n",
              " 44,\n",
              " 3,\n",
              " 1,\n",
              " 1372,\n",
              " 3,\n",
              " 244,\n",
              " 6,\n",
              " 8,\n",
              " 393,\n",
              " 1,\n",
              " 107,\n",
              " 2591,\n",
              " 1416,\n",
              " 3404,\n",
              " 6,\n",
              " 1,\n",
              " 122,\n",
              " 140,\n",
              " 127,\n",
              " 93,\n",
              " 716,\n",
              " 9,\n",
              " 8,\n",
              " 17,\n",
              " 246,\n",
              " 55,\n",
              " 1933,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 3669,\n",
              " 13,\n",
              " 1,\n",
              " 61,\n",
              " 7,\n",
              " 3619,\n",
              " 6,\n",
              " 412,\n",
              " 731,\n",
              " 2,\n",
              " 9,\n",
              " 7,\n",
              " 5,\n",
              " 1400,\n",
              " 4,\n",
              " 1508,\n",
              " 2548,\n",
              " 56,\n",
              " 1,\n",
              " 2038,\n",
              " 16,\n",
              " 273,\n",
              " 3,\n",
              " 2,\n",
              " 39,\n",
              " 1381,\n",
              " 14,\n",
              " 61,\n",
              " 2971,\n",
              " 3514,\n",
              " 66,\n",
              " 30,\n",
              " 91,\n",
              " 407,\n",
              " 313,\n",
              " 3333]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLycyw9HwSpR",
        "outputId": "06a65ccc-96fa-4794-936b-d0135523de73"
      },
      "source": [
        "print(np.asarray(X_train).shape) #np.asarray - Input data, in any form that can be converted to an array. This includes lists, lists of tuples, tuples, tuples of tuples, tuples of lists and ndarrays.\n",
        "print(np.asarray(X_test).shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(40000,)\n",
            "(10000,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZOKP1-54BQ0"
      },
      "source": [
        "# Perform padding on both train and test set, Set the maximum length of each list to 100 and add 0 padding to those lists that have a length < 100, until they reach a length of 100\n",
        "max_length = 100\n",
        "\n",
        "X_train = pad_sequences(X_train, maxlen=max_length, padding='post', truncating='post')\n",
        "X_test = pad_sequences(X_test, maxlen=max_length, padding='post', truncating='post')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_0sh8mI-b0k",
        "outputId": "cd87ca23-61bb-4c62-d8bc-7eea19b711c1"
      },
      "source": [
        "print('Encoded X Train\\n', X_train, '\\n')\n",
        "print('Encoded X Test\\n', X_test, '\\n')\n",
        "print('Maximum review length: ', max_length)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoded X Train\n",
            " [[   9    5   45 ...    1 1621  614]\n",
            " [ 130   68   10 ...  581   12 1991]\n",
            " [ 703 1264  111 ...    0    0    0]\n",
            " ...\n",
            " [ 760    8   25 ...    0    0    0]\n",
            " [   8  345   11 ...    0    0    0]\n",
            " [   8    5  510 ...   47    2  155]] \n",
            "\n",
            "Encoded X Test\n",
            " [[ 130   62  401 ...  791    3  632]\n",
            " [  10  104  674 ...  245 2497  389]\n",
            " [   1   17  881 ...    1  562    3]\n",
            " ...\n",
            " [ 418  140   65 ...    1  822    5]\n",
            " [  12  215   12 ...  595  494   32]\n",
            " [ 130  199  147 ...   88   16   43]] \n",
            "\n",
            "Maximum review length:  100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MtL-qCXWCDPV",
        "outputId": "ec644e85-1cab-4373-c179-68c2adba8c27"
      },
      "source": [
        "# Build LSTM Model for text classification\n",
        "\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense, Embedding, LSTM\n",
        "from tensorflow.python.keras.layers.embeddings import Embedding\n",
        "\n",
        "EMBEDDING_DIM = 100\n",
        "\n",
        "print('Build model...')\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(5000, EMBEDDING_DIM, input_length = max_length))\n",
        "model.add(LSTM(units=32,  dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(optimizer = 'RMSprop', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "print('Summary of the built model...')\n",
        "print(model.summary())"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build model...\n",
            "Summary of the built model...\n",
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_6 (Embedding)      (None, 100, 100)          500000    \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 32)                17024     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 517,057\n",
            "Trainable params: 517,057\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNCY7_LDdDrQ",
        "outputId": "89d45673-38b8-4119-9f88-8b38d086c92c"
      },
      "source": [
        "history = model.fit(X_train, y_train, batch_size=128, epochs=5, verbose=2, validation_split=0.2)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "250/250 - 45s - loss: 0.5036 - accuracy: 0.7499 - val_loss: 0.3824 - val_accuracy: 0.8340\n",
            "Epoch 2/5\n",
            "250/250 - 42s - loss: 0.3599 - accuracy: 0.8479 - val_loss: 0.3767 - val_accuracy: 0.8317\n",
            "Epoch 3/5\n",
            "250/250 - 42s - loss: 0.3240 - accuracy: 0.8657 - val_loss: 0.3864 - val_accuracy: 0.8380\n",
            "Epoch 4/5\n",
            "250/250 - 42s - loss: 0.3026 - accuracy: 0.8756 - val_loss: 0.4061 - val_accuracy: 0.8108\n",
            "Epoch 5/5\n",
            "250/250 - 42s - loss: 0.2864 - accuracy: 0.8830 - val_loss: 0.4034 - val_accuracy: 0.8292\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0cRoUQJhOac",
        "outputId": "0f83a321-0cc1-4472-ac60-7f86c5684e4e"
      },
      "source": [
        "print('Testing...')\n",
        "y_test = np.array(y_test)\n",
        "loss, accuracy = model.evaluate(X_test, y_test, batch_size=128)\n",
        "\n",
        "print('Test loss:', loss)\n",
        "print('Test accuracy:', accuracy)\n",
        "print(\"Accuracy: {0:.2%}\".format(accuracy))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing...\n",
            "79/79 [==============================] - 2s 28ms/step - loss: 0.3920 - accuracy: 0.8329\n",
            "Test loss: 0.39204397797584534\n",
            "Test accuracy: 0.8328999876976013\n",
            "Accuracy: 83.29%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAyuWP_gherC",
        "outputId": "f0183996-e546-4e63-c6bd-2c1f0a2a80f8"
      },
      "source": [
        "# Let us test some  samples\n",
        "test_sample_1 = \"This movie is fantastic! I really like it because it is so good!\"\n",
        "test_sample_2 = \"Good movie!\"\n",
        "test_sample_3 = \"Maybe I like this movie.\"\n",
        "test_sample_4 = \"Not to my taste, will skip and watch another movie\"\n",
        "test_sample_5 = \"if you like action, then this movie might be good for you.\"\n",
        "test_sample_6 = \"Bad movie!\"\n",
        "test_sample_7 = \"Not a good movie!\"\n",
        "test_sample_8 = \"This movie really sucks! Can I get my money back please?\"\n",
        "test_samples = [test_sample_1, test_sample_2, test_sample_3, test_sample_4, test_sample_5, test_sample_6, test_sample_7, test_sample_8]\n",
        "\n",
        "for each in test_samples:\n",
        "  filtered = [preprocess_text(each)]\n",
        "  tokenize_words = tokenizer.texts_to_sequences(filtered)\n",
        "  tokenize_words = pad_sequences(tokenize_words, maxlen=max_length, padding='post', truncating='post')\n",
        "  result = model.predict(tokenize_words)\n",
        "  if result >= 0.7:\n",
        "      print('positive == ',each)\n",
        "  else:\n",
        "      print('negative == ',each)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "positive ==  This movie is fantastic! I really like it because it is so good!\n",
            "negative ==  Good movie!\n",
            "negative ==  Maybe I like this movie.\n",
            "negative ==  Not to my taste, will skip and watch another movie\n",
            "negative ==  if you like action, then this movie might be good for you.\n",
            "negative ==  Bad movie!\n",
            "negative ==  Not a good movie!\n",
            "negative ==  This movie really sucks! Can I get my money back please?\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZsv_0V0kROl"
      },
      "source": [
        "# Summary\n",
        "# optimizer: adams\n",
        "# Test loss: 0.41735655069351196\n",
        "# Test accuracy: 83.14%\n",
        "\n",
        "# positive ==  This movie is fantastic! I really like it because it is so good!\n",
        "# negative ==  Good movie!\n",
        "# negative ==  Maybe I like this movie.\n",
        "# negative ==  Not to my taste, will skip and watch another movie\n",
        "# negative ==  if you like action, then this movie might be good for you.\n",
        "# negative ==  Bad movie!\n",
        "# negative ==  Not a good movie!\n",
        "# negative ==  This movie really sucks! Can I get my money back please?\n"
      ],
      "execution_count": 42,
      "outputs": []
    }
  ]
}